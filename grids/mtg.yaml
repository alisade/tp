---
git2consul:
  git2consul_status: good
admin_ips:
  users:
  users:
    akeller@cloudpassage.com: 76.89.164.115
    akellervpn@cloudpassage.com: 173.244.48.100
    zvickery@cloudpassage.com: 159.118.218.84
    trobbins@cloudpassage.com:
    aardestani@cloudpassage.com: 47.156.157.5
    alim@cloudpassage.com: 100.33.9.172
    talpert@cloudpassage.com: 34.208.62.171
    aadriasola@cloudpassage.com: 69.42.13.203
    vitaliy@cloudpassage.com: 71.94.73.141
    jcollier@cloudpassage.com: 173.92.26.196
    mandrus@cloudpassage.com: 68.99.32.87
    amansoor@cloudpassage.com:
    vaher@cloudpassage.com:
    tcummings@cloudpassage.com:
    kuga@cloudpassage.com:
    dangal@cloudpassage.com:
    cwardall@cloudpassage.com:
    kjanakiraman@cloudpassage.com:
    jcordova@cloudpassage.com:
    vmanda@cloudpassage.com:

kong:
  REPORTING_API_EXTERNAL_WHITELIST: '10.0.0.0/8'

3rdparty:
  new_relic_license_key: dc7d9326185261dc8f38bdbd11db15749dc9427b
  datadog_api_key: 6d3fccd2292fa567e2e335dbf09a3caa
  airbrake_project_key: 1a92e69dfd661dcd0c93af2fa7219083
  airbrake_project_id: 143730

kafka-connect:
  worker_count: 8
  cpus: 4
  mem: 4096
  SVM_FINDING_EVENTS_TASKS_MAX: 20
  CVM_FINDING_EVENTS_TASKS_MAX: 12
  ISSUE_EVENTS_TASKS_MAX: 6

reporting-service:
  mem: 4096

ninjas:
  repo_url: https://production.packages.cloudpassage.com
  cassandra_keyspace: cloudpassage
  env:
    CP_POSTGRES_HOST: pgbouncer.marathon.mesos
    API_CPUS: 2.0
    API_MEM: 3072
    PORTAL_CPUS: 2.0
    PORTAL_MEM: 3072
    GRID_CPUS: 2.0
    GRID_MEM: 2048
    WORKER_DEFAULT_CPUS: 1.0
    WORKER_MAIL_INSTANT_ALERTS_MEM: 2048
    WORKER_MAIL_DIGEST_ALERTS_MEM: 2048
    WORKER_FACTS_MEM: 1024
    WORKER_FIM_MEM: 4096
    WORKER_REACTIVATE_AGENT_MEM: 1024
    WORKER_SNAPSHOT_COUNT_MEM: 1024
    WORKER_SVM_MEM: 1024
    WORKER_SVM_ROLE: slave_worker_high_density
    WORKER_SCA_MEM: 1024
    WORKER_SCA_ROLE: slave_worker_high_density
    WORKER_SAM_MEM: 1024
    WORKER_SVA2_MEM: 4096
    WORKER_SVA22_MEM: 8192
    WORKER_TD_MEM: 1024
    WORKER_TD_ROLE: slave_worker_high_density
    WORKER_USER_REQUESTS_SVA2_MEM: 1024
    WORKER_USER_REQUESTS_SVA22_MEM: 1024
    AGENT_EVENTS_COLLECTOR_MEM: 8192
    AGENT_EVENTS_ROUTER_MEM: 1024
    JOB_CASSANDRA_MIGRATE_MEM: 4096
    CP_MAILER_ASSET_HOST: https://portal.cloudpassage.com
    ES_EVENTS_SHARD_COUNT: 60
    CP_S3_AWS_FUGU_BUCKET: ng-fugu-blue
    CP_FUGU_HOST: https://fugu-blue.cloudpassage.com
    CP_CASSANDRA_KEYSPACE: cloudpassage
    CP_GRID_IPS: grid.cloudpassage.com
    CP_REQUIRE_AUTH_FOR_REGISTRATION: 0
    CP_ZUORA_SERVER: https://www.zuora.com/apps/services/a/71.0
    CP_ZUORA_PRODUCTION_PLANS: 1
    CP_S3_BUCKET_NAME: cphalo-production
    CP_MIGRATION_GRID_URL: grid.cloudpassage.com
    CP_REPO_URL: https://production.packages.cloudpassage.com
    CP_CONNECTOR_REPO_URL: https://production.packages.cloudpassage.com/connector
    CP_LINUX_DAEMON_VERSION: 4.1.1
    CP_WINDOWS_DAEMON_VERSION: 4.1.0
    CP_LINUX_CONNECTOR_DAEMON_VERSION: 4.1.1
    CP_IMAGE_COLLECTOR_SERVICE_GRID_URL: https://containers.cloudpassage.com
    CP_ES_EVENTS_URL: http://es-events-mtg.ng.cloudpassage.com:9200
  vips:
    api: api.cloudpassage.com
    grid: grid.cloudpassage.com
    portal: portal.cloudpassage.com
    containers: containers.cloudpassage.com
  kafka:
    topic:
      # Values must be valid JSON or it will not work!
      reload_agent_group_state: '{ "partitions": 64, "config":[ "segment.bytes=1000000","retention.ms=3600000","delete.retention.ms=3600000" ], "replication-factor": 3 }'
      agent_events: '{ "partitions": 128, "config":[ "segment.bytes=5000000" ], "replication-factor": 3 }'
      events: '{ "partitions": 64, "config":[ "segment.bytes=5000000" ], "replication-factor": 3 }'
      events_index: '{ "partitions": 128, "config":[ "segment.bytes=5000000" ], "replication-factor": 3 }'
      svm: '{ "partitions": 128, "config":[ "segment.bytes=5000000" ], "replication-factor": 3 }'
      td: '{ "partitions": 128, "config":[ "segment.bytes=5000000" ], "replication-factor": 3 }'
      sva2: '{ "partitions": 128, "config":[ "segment.bytes=5000000" ], "replication-factor": 3 }'
      sva22: '{ "partitions": 128, "config":[ "segment.bytes=5000000" ], "replication-factor": 3 }'
      fim: '{ "partitions": 128, "config":[ "segment.bytes=5000000" ], "replication-factor": 3 }'
      lids: '{ "partitions": 128, "config":[ "segment.bytes=5000000" ], "replication-factor": 3 }'
      sca: '{ "partitions": 128, "config":[ "segment.bytes=5000000" ], "replication-factor": 3 }'
      delete_server: '{ "partitions": 128, "config":[ "segment.bytes=5000000" ], "replication-factor": 3 }'

terraform_overrides:
  TF_VAR_research_rds_enable: true
  TF_VAR_rds_backup_count: 30
  TF_VAR_environment: "production"
  # Setting the ssh public key used to create the stack so it will complete in jenkins
  TF_VAR_ssh_public_key: "ssh-rsa AAAAB3NzaC1yc2EAAAADAQABAAABAQC4vXV8G7ryAttd306l74173PIDUlxMGKjlVao2aee6KS/RG7Z8bmAY3BrmS3nOwl+TDh6YoyKd3Z6+ax5vOcPg8GC10lxmsr54EVTudHY76SsC4ZtT7X6DClkg8ZbTZbbAa09kArUC0T4ToYR1NYIpVyzFnMIytBL62cDZlikAD93B5NC4CbYWEfvVLoJ4Pf2MCSowhoUtCXq1qwTtMFXM+30xYDS+AYUSu0NquA3el5egJ8Ujp5BkH2BqSiugOxF1007YZxktxTpQ417V2OYZF5Wa5ws1rCXa2QopWHJfvXqD77oPmSN7TkEWHekQI1/9MHoLoVl1C0b0coEQQgz5 brent@Brents-MacBook.2015"
  TF_VAR_cass_count: '{ us-west-2a=11, us-west-2b=11, us-west-2c=11 }'
  TF_VAR_cassandra_ebs_size: '2000'
  TF_VAR_elasticsearch_count: '{ us-west-2a=10, us-west-2b=10, us-west-2c=10 }'
  TF_VAR_elasticsearch_ebs_size: 1000
  TF_VAR_slave_count: '{ us-west-2a=2, us-west-2b=2, us-west-2c=2 }'
  TF_VAR_public_slave_count: '{ us-west-2a=1, us-west-2b=1, us-west-2c=1 }'
  TF_VAR_public_slave_total: 3
  TF_VAR_kafka_count: '{us-west-2a=1, us-west-2b=1, us-west-2c=1 }'
  TF_VAR_kafka_instance_type: "m4.2xlarge"
  TF_VAR_kafka_ebs_size: 4000
  TF_VAR_kafka_heap: '5G'
  TF_VAR_elasticsearch_instance_type: "r4.2xlarge"
  TF_VAR_elasticsearch_master_instance_type: "m3.xlarge"
  TF_VAR_es_events_enable: 'true'
  TF_VAR_cassandra_instance_type: "i3.xlarge"
  TF_VAR_master_instance_type: "m3.2xlarge"
  TF_VAR_public_slave_instance_type: "m3.2xlarge"
  TF_VAR_slave_instance_type: "c3.8xlarge"
  TF_VAR_rds: '{ multi_az=true, allocated_storage="3000", storage_type="gp2", apply_immediately=true, instance_type="db.m4.2xlarge" }'
  TF_VAR_rdskong: '{ multi_az=true, allocated_storage="20", storage_type="gp2", apply_immediately=true, instance_type="db.t2.medium" }'
  TF_VAR_es_domain_instance_type: "m4.large.elasticsearch"
  TF_VAR_zookeeper_instance_type: "m4.large"
  TF_VAR_es_domain_volume_size: 300
  TF_VAR_cass_cluster_name: "prod cluster"
  TF_VAR_cass_multiregion_enable: true
  TF_VAR_cass_internode_encryption: none
  TF_VAR_cass_endpoint_snitch: org.apache.cassandra.locator.Ec2MultiRegionSnitch
  TF_VAR_cass_suspended_processes: "Launch,Terminate,HealthCheck,ReplaceUnhealthy"
  TF_VAR_cg_cassandra_location: "35.160.217.228/32,52.26.24.28/32,34.209.210.215/32,34.223.242.21/32,35.165.36.168/32,52.33.150.111/32,52.89.103.215/32,34.210.176.71/32,52.39.26.49/32,52.89.96.207/32,34.210.63.8/32,34.210.116.73/32,34.210.226.137/32,52.36.224.121/32,34.208.37.15/32,34.210.161.13/32,52.43.16.137/32,34.210.49.241/32,34.210.213.187/32,34.210.111.126/32,35.167.14.74/32,34.210.244.60/32,34.209.105.160/32,54.70.152.183/32,35.165.229.87/32,54.148.232.160/32,52.27.59.111/32,52.42.211.210/32,34.209.94.104/32,52.88.108.165/32,34.210.205.175/32,35.161.207.222/32"
  
  TF_VAR_rdsmetabase_enable: true

  # Worker Slaves
  TF_VAR_worker_slave_count: '{ us-west-2a=0, us-west-2b=0, us-west-2c=0 }'
  TF_VAR_worker_slave_instance_type: "c3.8xlarge"
  
  # High Density Worker Slaves
  TF_VAR_enable_high_density_workers: true
  TF_VAR_worker_slave_high_density_count: 6
  TF_VAR_worker_slave_high_density_instance_type: c4.8xlarge
  
  # Spot Fleet Workers
  TF_VAR_worker_slave_spot_fleet_enable: true
  TF_VAR_worker_slave_spot_fleet_target_capacity: 1500

  # Change this value (doesn't matter what) to trigger a new spot fleet
  # https://github.com/terraform-providers/terraform-provider-aws/issues/741
  TF_VAR_worker_slave_spot_fleet_valid_until: "2022-12-22T22:22:24Z"

  # Reporting
  TF_VAR_kafka_kinesis_topics: csm_external_identifier_events,csm_finding_events,csm_policy_events,cve_base_metric_events,cve_entry_events,cve_exception_events,cve_vulnerable_software_events,group_events,issue_events,rule_events,scan_events,server_events,svm_finding_events,user_events,firewall_policy_events
  TF_VAR_emr_enable: 'true'
  TF_VAR_kinesis_retention_period_default: 168
  TF_VAR_rdsreporting: '{ multi_az=true, allocated_storage="100", storage_type="gp2", apply_immediately=true, instance_type="db.t2.medium" }'
  TF_VAR_consistent_view_enable: true
  TF_VAR_override_streaming_profiles: false
  #TF_VAR_kinesis_retention_period: '{ svm_finding_events="168" }'
  TF_VAR_emr_version: "5.8.0"
  TF_VAR_emr_enable_reporting_green: "true"
  TF_VAR_emr_enable_reporting_blue: "false"
  TF_VAR_emr_report_dns_target: "green"
  TF_VAR_emr_streaming_dynamic_allocation: "false"
  TF_VAR_kinesis_shard_default: 1
  TF_VAR_streaming_spark_profiles: '{ issue_events="high_throughput", scan_events="high_throughput", server_events="high_throughput", svm_finding_events="4c16g_rc2", csm_finding_events="4c16g" }'
  TF_VAR_streamingemr: '{ master="r4.xlarge", core="r4.xlarge", core_count=9 }'

  # OPS-6436: Use ondemand for prod
  TF_VAR_spot_pricing: '{ c4.large="" c4.xlarge="" c4.2xlarge="" c4.4xlarge="" c4.8xlarge="" m4.large="" m4.xlarge="" m4.2xlarge="" m4.4xlarge="" m4.10xlarge="" m4.16xlarge="" m3.medium="", m3.large="", m3.xlarge="", m3.2xlarge="", m4.xlarge="", c3.large="", c3.xlarge="", c3.2xlarge="", c3.4xlarge="", c3.8xlarge="", r3.large="", r3.xlarge="", r3.2xlarge="", r3.4xlarge="", r3.8xlarge="", i2.xlarge="", i2.2xlarge="",  i2.4xlarge="", i2.8xlarge="", d2.xlarge="", d2.2xlarge="", d2.4xlarge="", d2.8xlarge="" }'

report_scheduler:
  secrets:
    ninjas_api_key_id: AQECAHggbZuboIok9gynsvchgYmgpCEaXihwRBaoOlahzOyJ8wAAAGYwZAYJKoZIhvcNAQcGoFcwVQIBADBQBgkqhkiG9w0BBwEwHgYJYIZIAWUDBAEuMBEEDATEDJEDL/+YCRBT2QIBEIAjxHsOOu9bv+nRN3+DyP+z/ZkIvc/Mx6F7qGFWHjCnxwUzmWg=
    ninjas_api_key: AQECAHggbZuboIok9gynsvchgYmgpCEaXihwRBaoOlahzOyJ8wAAAH4wfAYJKoZIhvcNAQcGoG8wbQIBADBoBgkqhkiG9w0BBwEwHgYJYIZIAWUDBAEuMBEEDOkFtK4ziad8ECiGrQIBEIA7S4z1+8nvVyPb+LPM6+r2QBtSDDbx3V83RTM6lRWSuziRhHdLqdgvFKh3Q0oWMEUJbAamR2WvKMmZl2M=

sni_overrides:
  enabled: true

containers:
  CP_CASSANDRA_DEFAULT_CONSISTENCY: local_quorum

agent-events-collector:
  MEM: 8192

agent-events-router:
  MEM: 4096

event-indexer:
  env:
    CP_ELASTICSEARCH_HOSTS: "http://es-events-mtg.ng.cloudpassage.com:9200"

gridbot:
  permissions:
    'JenkinsBot:*':
      allowusers:
        alfonso:
        vitaliy:
        amansoor:
        vaibhav:
        theocummings:
        kuga:
        dilipangal:
        wookie:
        kishore:
        joe:
        vmanda:
        dsrgyv:
        abarkouski:
        marsel.shiriyazdanov:
        sasha:
        aardestani:
        akeller:
        trobbins:
        alim:
        bcross:
        dima:
        j:
        zvickery:
        theo:
        mandrus:
    'help':
      allowusers:
        '#mtg/*':
